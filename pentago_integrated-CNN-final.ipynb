{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jgaustad/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from helper_func import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import keras\n",
    "from multiprocessing import Pool\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from collections import deque\n",
    "from keras.activations import relu, linear\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pentago:\n",
    "    \"\"\"\n",
    "    The class contains the boardgame and allows agents to execute moves. It saves all gameplay and boardstates in the history attrib.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state = None):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        #print('initializing')\n",
    "        \n",
    "        if state == None:\n",
    "            self.state = state = np.zeros((6,6), dtype=np.int)\n",
    "        self.history = []\n",
    "        self.winner = None\n",
    "        self.gameover = False\n",
    "        self.player_turn = 1\n",
    "    \n",
    "    def current_board_state(self):\n",
    "        # need to return a copy or bad stuff happens\n",
    "        return copy.copy(self.state)\n",
    "    \n",
    "    def game_history(self, player, move, cuad, rotatation):\n",
    "        self.history.append((boardstate_to_ideal_key(self.state), ideal_state(self.state), player, move, cuad, rotatation))\n",
    "        #return self.history\n",
    "\n",
    "    def find_winner(self, board_state):\n",
    "        player1_win = False\n",
    "        player_min1_win = False\n",
    "        diagonal1 = board_state.diagonal()\n",
    "        diagonal2 = np.fliplr(board_state).diagonal()\n",
    "        winning_slices =  np.vstack([board_state[1:,:].T, board_state[:-1,:].T, # all columns\n",
    "                              board_state[:,1:], board_state[:,:-1], # all rows\n",
    "                              diagonal1[1:], diagonal1[:-1], # diagonal 1\n",
    "                              diagonal2[1:],diagonal2[1:], # diagonal 2\n",
    "                              board_state.diagonal(offset=1), board_state.diagonal(offset=-1), # diagonal offsets \n",
    "                              np.fliplr(board_state).diagonal(offset=1), np.fliplr(board_state).diagonal(offset=-1)] ) # diagonal offsets\n",
    "        sums = np.dot(winning_slices, np.array([1,1,1,1,1]))\n",
    "        if 5 in sums: player1_win = True\n",
    "        if -5 in sums: player_min1_win = True\n",
    "        if player1_win == True or player_min1_win == True:\n",
    "           # print(\"Player 1 winner?\", player1_win, \"Player -1 winner?\", player_min1_win)\n",
    "            self.gameover = True\n",
    "            if player1_win == True:\n",
    "                self.winner = 1\n",
    "            elif player_min1_win ==True:\n",
    "                self.winner = -1\n",
    "            self.history.append(self.winner)\n",
    "        return \"Win\"\n",
    "\n",
    "    def check_gameover(self):\n",
    "        if not 0 in self.state:\n",
    "              self.gameover = True\n",
    "              #print(\"The game board is full!\")\n",
    "        \n",
    "    def full_move(self, move, cuad, direction, player, dtype=np.int):\n",
    "        if player != self.player_turn:\n",
    "            print( \"error, wrong player turn. No move taken.\")\n",
    "            return 'Error, wrong player turn.'\n",
    "        self.state = fullmove(self.state,move, cuad, direction, player)\n",
    "\n",
    "\n",
    "        self.game_history(move, player, cuad, direction)\n",
    "        self.find_winner(self.state) #return in find_winner if a winner is found\n",
    "        self.check_gameover() #return in check_gameover\n",
    "        if player == 1:\n",
    "            self.player_turn = -1\n",
    "        else:\n",
    "            self.player_turn = 1\n",
    "        #print('Successful Move')\n",
    "        return self.state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    def __init__(self,list_density=None,lr=0.02):\n",
    "        self.model = self.build_model(list_density,lr)\n",
    "\n",
    "    def build_model(self,den,lr):\n",
    "        model = Sequential()\n",
    "        #model.add(tf.keras.Input(shape=(6,6,2,)))\n",
    "        #for layer in den:\n",
    "        model.add(Conv2D(\n",
    "                            filters = 64, \n",
    "                            kernel_size = (3,3),\n",
    "                            strides = (3,3),\n",
    "                            padding = 'valid',\n",
    "                            activation = relu,\n",
    "                            input_shape = (6,6,2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation = relu))\n",
    "        model.add(Dense(128, activation = relu))\n",
    "\n",
    "\n",
    "        model.add(Dense(1, activation=linear))\n",
    "        \n",
    "        model.compile(loss=mean_squared_error,optimizer=Adam(lr=lr))\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def update_model(self,states_batch, q_batch, epochs = 1):\n",
    "\n",
    "        self.model.fit(states_batch,q_batch,epochs = epochs, verbose=1)\n",
    "\n",
    "    def predict_model(self, state_batch):\n",
    "        return self.model.predict_on_batch(state_batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn_agent:\n",
    "    \n",
    "    def __init__(self, nn, player = 1, epsilon = 1, epsilon_decay = .99995, epsilon_min = .5):\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.nn = nn\n",
    "        self.player = player\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "            \n",
    "    def get_avail_moves(self,boardstate):\n",
    "        \"\"\"\n",
    "        This method creates a list with available spaces in the board and combination of quadrant and rotation\n",
    "        The input is the board state (6x6) numpy array\n",
    "        \"\"\"\n",
    "        x = np.where(boardstate == 0)\n",
    "        #print(x)\n",
    "        available_positions_for_placement = list(zip(x[0], x[1]))\n",
    "        \n",
    "        # all available positions (p), quadrants(q), rotations(r)\n",
    "        available_moves = [(p,q,r) for p in available_positions_for_placement for q in [1,2,3,4] for r in [-1,1]]\n",
    "        #print(len(available_moves))\n",
    "        return available_moves\n",
    "    \n",
    "    def get_possible_next_boardstates(self, boardstate):\n",
    "        next_possible_boardstates = defaultdict(list)\n",
    "        for move in self.get_avail_moves(boardstate):\n",
    "            possible_boardstate = fullmove(boardstate,*move, self.player)\n",
    "            #print(possible_boardstate)\n",
    "            key = boardstate_to_ideal_key(possible_boardstate)\n",
    "            cnn_input = boardstate_to_cnn_input(possible_boardstate)\n",
    "            next_possible_boardstates[key].append((cnn_input, move))\n",
    "            \n",
    "        return next_possible_boardstates\n",
    "    \n",
    "    def make_move(self, game):\n",
    "        \n",
    "        # get the current boardstate from the pentago class\n",
    "        boardstate = game.current_board_state()\n",
    "        \n",
    "        # get possible next possible boardstates\n",
    "        t0 = time.time()\n",
    "        next_possible_boardstates = self.get_possible_next_boardstates(boardstate)\n",
    "        key_list = list(next_possible_boardstates.keys())\n",
    "\n",
    "        # determine if to take random move\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            random_bs = random.choice(key_list)\n",
    "            random_mv = next_possible_boardstates[random_bs][0][1] # capture the move needed\n",
    "            \n",
    "            game.full_move(*random_mv,self.player)\n",
    "            \n",
    "        else:\n",
    "            #print(\"not random\", self.player)\n",
    "           # t0 = time.time()\n",
    "            nn_input_boardstate = []\n",
    "            move = []\n",
    "            for k,v in next_possible_boardstates.items():\n",
    "                nn_input_boardstate.append(v[0][0])\n",
    "                #print(v[0][0].shape)\n",
    "                move.append(v[0][1])\n",
    "\n",
    "            nn_input_batch = np.array(nn_input_boardstate)\n",
    "\n",
    "            q_values = self.nn.predict_model(nn_input_batch)\n",
    "            q_values *= self.player\n",
    "\n",
    "            max_q = np.argmax(q_values)\n",
    "\n",
    "            mv_to_take = move[max_q]\n",
    "            game.full_move(*mv_to_take, self.player)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(history, decay_factor = .9):\n",
    "    winner = history[-1]\n",
    "    nn_inputs = []\n",
    "    rewards = []\n",
    "    for boardposition in history[-2::-1]:\n",
    "        nn_inputs.append(boardposition[1])\n",
    "        rewards.append(winner)\n",
    "        winner *= decay_factor\n",
    "    return nn_inputs, rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_sim(agents):\n",
    "    '''This function simulates a game and allows for multiprocessing calls.'''\n",
    "    agent1, agent2 = agents\n",
    "    g = pentago()\n",
    "    while g.gameover == False:\n",
    "        agent1.make_move(g)\n",
    "        if g.gameover ==True: break\n",
    "        agent2.make_move(g)\n",
    "    #print('gameover.')\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_sim_parallel_nn(agent1, agent2, n_steps = 1, games_per_step = 32, nn_to_update = [], parallel_threads = 6):\n",
    "    game_times = []\n",
    "    evals = []\n",
    "    eval_times = []\n",
    "    epsilons = []\n",
    "    nn_update_times = []\n",
    "    winner_list = []\n",
    "    running_boardstates = []\n",
    "    running_rewards = []\n",
    "    \n",
    "    for n in range(n_steps):\n",
    "        print('game_step', n, end = ' ')\n",
    "        game_start = time.time()\n",
    "        \n",
    "        #if __name__ == '__main__':\n",
    "        #    with Pool(parallel_threads) as p:\n",
    "        #        game_returns = p.map(little_sim, [(agent1,agent2)]*games_per_step)\n",
    "        game_returns = [little_sim((agent1,agent2)) for x in range(games_per_step)] #comment out parallelilization if needed.\n",
    "        \n",
    "            \n",
    "        game_times.append(time.time()-game_start)\n",
    "            \n",
    "        player1_winner = 0\n",
    "        player2_winner = 0\n",
    "        # check for winner and create update batch\n",
    "        nn_input_batch = []\n",
    "        rewards_for_batch = []\n",
    "        for game in game_returns:\n",
    "            if game.winner:\n",
    "                if game.winner == 1: player1_winner += 1\n",
    "                else: player2_winner += 1\n",
    "                \n",
    "                # accumulate rewards and inputs for training\n",
    "                boardstates, rewards = reward_func(game.history)\n",
    "                nn_input_batch += [boardstate_to_cnn_input(bs) for bs in boardstates] # add nn_inputs to training list (x)\n",
    "                rewards_for_batch += rewards # add rewards to training list (Y)\n",
    "        winner_list.append(player1_winner)\n",
    "        \n",
    "        # evaluate the model\n",
    "        t0 = time.time()\n",
    "        for nn in nn_to_update:\n",
    "            evals.append(nn.model.evaluate(np.array(nn_input_batch), np.array(rewards_for_batch)))\n",
    "        eval_times.append(time.time() - t0)\n",
    "\n",
    "        \n",
    "        # train the neural network\n",
    "        t0 = time.time()\n",
    "        print(f\"updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\")\n",
    "        running_boardstates += nn_input_batch\n",
    "        running_rewards += rewards_for_batch\n",
    "        for nn in nn_to_update:\n",
    "            nn.update_model(np.array(running_boardstates[-5000:]), np.array(running_rewards[-5000:]))\n",
    "        nn_update_times.append(time.time() - t0)\n",
    "\n",
    "\n",
    "        print(\"player 1 wins:\", player1_winner)\n",
    "        print(\"player 2 wins:\", player2_winner)\n",
    "        #print(\"simulations took\", game_times[-1], \"seconds.\")\n",
    "        print(\"neural network update time:\", nn_update_times[-1], \"seconds.\")\n",
    "        try:\n",
    "            print(\"eval score on batch:\", evals[-1])\n",
    "        except:\n",
    "            pass\n",
    "        print(\"epsilons agent1 and agent2:\", agent1.epsilon, agent2.epsilon)\n",
    "        epsilons.append((agent1.epsilon, agent2.epsilon))\n",
    "        if agent1.epsilon > agent1.epsilon_min: agent1.epsilon *= agent1.epsilon_decay\n",
    "        else: agent1.epsilon == agent1.epsilon_min\n",
    "        if agent2.epsilon > agent2.epsilon_min: agent2.epsilon *= agent2.epsilon_decay\n",
    "        else: agent2.epsilon == agent2.epsilon_min\n",
    "\n",
    "    # end of simulation runs, save q_table(s) to disk\n",
    "    nn_num = 1\n",
    "    time_str = str(datetime.now())[:19].replace(':','_')\n",
    "    for nn in nn_to_update:\n",
    "        with open(f'CNN_{nn_num}_'+time_str+'.pickle', 'wb') as file:\n",
    "            pickle.dump(nn, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        nn_num += 1\n",
    "    \n",
    "    return epsilons, nn_update_times, winner_list, evals, eval_times\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 2, 2, 64)          1216      \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,033\n",
      "Trainable params: 100,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 64)          1216      \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,033\n",
      "Trainable params: 100,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#NOTE: You will overwrite a trained model if run this after training.\n",
    "nn_1 = cnn_model()\n",
    "nn_2 = cnn_model()\n",
    "agent1 = nn_agent(player = 1,  nn = nn_1, epsilon_min = 0, epsilon_decay = .99, epsilon = .3)\n",
    "agent2 = nn_agent(player = -1,  nn = nn_2, epsilon_min = 0, epsilon_decay = .99, epsilon = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 0s 436us/step\n",
      "updating with 893, 893 training batch.\n",
      "Epoch 1/1\n",
      "893/893 [==============================] - 2s 2ms/step - loss: 0.2610\n",
      "player 1 wins: 16\n",
      "player 2 wins: 15\n",
      "neural network update time: 2.013617992401123 seconds.\n",
      "eval score on batch: 0.19536430767475557\n",
      "epsilons agent1 and agent2: 0.3 1\n",
      "823/823 [==============================] - 0s 53us/step\n",
      "updating with 823, 823 training batch.\n",
      "Epoch 1/1\n",
      "1716/1716 [==============================] - 0s 186us/step - loss: 0.1850\n",
      "player 1 wins: 15\n",
      "player 2 wins: 14\n",
      "neural network update time: 0.32364511489868164 seconds.\n",
      "eval score on batch: 0.190859961317782\n",
      "epsilons agent1 and agent2: 0.297 0.99\n",
      "830/830 [==============================] - 0s 52us/step\n",
      "updating with 830, 830 training batch.\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 0s 189us/step - loss: 0.1840\n",
      "player 1 wins: 15\n",
      "player 2 wins: 15\n",
      "neural network update time: 0.48554301261901855 seconds.\n",
      "eval score on batch: 0.1882652458297201\n",
      "epsilons agent1 and agent2: 0.29402999999999996 0.9801\n",
      "834/834 [==============================] - 0s 42us/step\n",
      "updating with 834, 834 training batch.\n",
      "Epoch 1/1\n",
      "3380/3380 [==============================] - 1s 193us/step - loss: 0.1862\n",
      "player 1 wins: 14\n",
      "player 2 wins: 16\n",
      "neural network update time: 0.6594150066375732 seconds.\n",
      "eval score on batch: 0.19422251753491176\n",
      "epsilons agent1 and agent2: 0.29108969999999995 0.9702989999999999\n",
      "845/845 [==============================] - 0s 46us/step\n",
      "updating with 845, 845 training batch.\n",
      "Epoch 1/1\n",
      "4225/4225 [==============================] - 1s 192us/step - loss: 0.1884\n",
      "player 1 wins: 19\n",
      "player 2 wins: 13\n",
      "neural network update time: 0.8184208869934082 seconds.\n",
      "eval score on batch: 0.19828297382540253\n",
      "epsilons agent1 and agent2: 0.28817880299999993 0.96059601\n",
      "818/818 [==============================] - 0s 41us/step\n",
      "updating with 818, 818 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 189us/step - loss: 0.1886\n",
      "player 1 wins: 18\n",
      "player 2 wins: 11\n",
      "neural network update time: 0.9543709754943848 seconds.\n",
      "eval score on batch: 0.19208366870151464\n",
      "epsilons agent1 and agent2: 0.28529701496999993 0.9509900498999999\n",
      "753/753 [==============================] - 0s 47us/step\n",
      "updating with 753, 753 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 218us/step - loss: 0.1917\n",
      "player 1 wins: 21\n",
      "player 2 wins: 10\n",
      "neural network update time: 1.0946927070617676 seconds.\n",
      "eval score on batch: 0.2068359304471795\n",
      "epsilons agent1 and agent2: 0.28244404482029994 0.9414801494009999\n",
      "794/794 [==============================] - 0s 43us/step\n",
      "updating with 794, 794 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 184us/step - loss: 0.1905\n",
      "player 1 wins: 28\n",
      "player 2 wins: 4\n",
      "neural network update time: 0.9293270111083984 seconds.\n",
      "eval score on batch: 0.18552727055189291\n",
      "epsilons agent1 and agent2: 0.27961960437209693 0.9320653479069899\n",
      "805/805 [==============================] - 0s 57us/step\n",
      "updating with 805, 805 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 211us/step - loss: 0.1853\n",
      "player 1 wins: 26\n",
      "player 2 wins: 6\n",
      "neural network update time: 1.0603199005126953 seconds.\n",
      "eval score on batch: 0.17888709045801982\n",
      "epsilons agent1 and agent2: 0.276823408328376 0.92274469442792\n",
      "773/773 [==============================] - 0s 49us/step\n",
      "updating with 773, 773 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 199us/step - loss: 0.1792\n",
      "player 1 wins: 24\n",
      "player 2 wins: 8\n",
      "neural network update time: 1.0018949508666992 seconds.\n",
      "eval score on batch: 0.18374458989574252\n",
      "epsilons agent1 and agent2: 0.27405517424509224 0.9135172474836407\n",
      "804/804 [==============================] - 0s 49us/step\n",
      "updating with 804, 804 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 189us/step - loss: 0.1746\n",
      "player 1 wins: 26\n",
      "player 2 wins: 6\n",
      "neural network update time: 0.9535338878631592 seconds.\n",
      "eval score on batch: 0.16597544969017827\n",
      "epsilons agent1 and agent2: 0.2713146225026413 0.9043820750088043\n",
      "796/796 [==============================] - 0s 65us/step\n",
      "updating with 796, 796 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 218us/step - loss: 0.1650\n",
      "player 1 wins: 26\n",
      "player 2 wins: 6\n",
      "neural network update time: 1.0954837799072266 seconds.\n",
      "eval score on batch: 0.15814979071143884\n",
      "epsilons agent1 and agent2: 0.2686014762776149 0.8953382542587163\n",
      "726/726 [==============================] - 0s 47us/step\n",
      "updating with 726, 726 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 202us/step - loss: 0.1673\n",
      "player 1 wins: 21\n",
      "player 2 wins: 9\n",
      "neural network update time: 1.0172951221466064 seconds.\n",
      "eval score on batch: 0.20036616297977522\n",
      "epsilons agent1 and agent2: 0.26591546151483875 0.8863848717161291\n",
      "805/805 [==============================] - 0s 43us/step\n",
      "updating with 805, 805 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 188us/step - loss: 0.1739\n",
      "player 1 wins: 21\n",
      "player 2 wins: 10\n",
      "neural network update time: 0.9495859146118164 seconds.\n",
      "eval score on batch: 0.1894501376295497\n",
      "epsilons agent1 and agent2: 0.2632563068996904 0.8775210229989678\n",
      "813/813 [==============================] - 0s 47us/step\n",
      "updating with 813, 813 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 188us/step - loss: 0.1683\n",
      "player 1 wins: 30\n",
      "player 2 wins: 2\n",
      "neural network update time: 0.9481110572814941 seconds.\n",
      "eval score on batch: 0.11627779243717848\n",
      "epsilons agent1 and agent2: 0.2606237438306935 0.8687458127689781\n",
      "784/784 [==============================] - 0s 59us/step\n",
      "updating with 784, 784 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 210us/step - loss: 0.1697\n",
      "player 1 wins: 24\n",
      "player 2 wins: 8\n",
      "neural network update time: 1.059027910232544 seconds.\n",
      "eval score on batch: 0.18009349947073022\n",
      "epsilons agent1 and agent2: 0.2580175063923865 0.8600583546412883\n",
      "810/810 [==============================] - 0s 65us/step\n",
      "updating with 810, 810 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 216us/step - loss: 0.1722\n",
      "player 1 wins: 23\n",
      "player 2 wins: 9\n",
      "neural network update time: 1.0909712314605713 seconds.\n",
      "eval score on batch: 0.1842666834776784\n",
      "epsilons agent1 and agent2: 0.25543733132846264 0.8514577710948754\n",
      "773/773 [==============================] - 0s 53us/step\n",
      "updating with 773, 773 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 190us/step - loss: 0.1727\n",
      "player 1 wins: 28\n",
      "player 2 wins: 4\n",
      "neural network update time: 0.956179141998291 seconds.\n",
      "eval score on batch: 0.14500612058323767\n",
      "epsilons agent1 and agent2: 0.252882958015178 0.8429431933839266\n",
      "787/787 [==============================] - 0s 51us/step\n",
      "updating with 787, 787 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 201us/step - loss: 0.1687\n",
      "player 1 wins: 24\n",
      "player 2 wins: 7\n",
      "neural network update time: 1.0156679153442383 seconds.\n",
      "eval score on batch: 0.1682110431673907\n",
      "epsilons agent1 and agent2: 0.25035412843502625 0.8345137614500874\n",
      "784/784 [==============================] - 0s 44us/step\n",
      "updating with 784, 784 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 183us/step - loss: 0.1616\n",
      "player 1 wins: 24\n",
      "player 2 wins: 7\n",
      "neural network update time: 0.9243898391723633 seconds.\n",
      "eval score on batch: 0.16670523507862675\n",
      "epsilons agent1 and agent2: 0.24785058715067598 0.8261686238355865\n",
      "781/781 [==============================] - 0s 47us/step\n",
      "updating with 781, 781 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 192us/step - loss: 0.1617\n",
      "player 1 wins: 26\n",
      "player 2 wins: 5\n",
      "neural network update time: 0.9673740863800049 seconds.\n",
      "eval score on batch: 0.1481357790969751\n",
      "epsilons agent1 and agent2: 0.2453720812791692 0.8179069375972307\n",
      "810/810 [==============================] - 0s 61us/step\n",
      "updating with 810, 810 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 232us/step - loss: 0.1770\n",
      "player 1 wins: 17\n",
      "player 2 wins: 15\n",
      "neural network update time: 1.166964054107666 seconds.\n",
      "eval score on batch: 0.23610729442012532\n",
      "epsilons agent1 and agent2: 0.24291836046637752 0.8097278682212583\n",
      "778/778 [==============================] - 0s 45us/step\n",
      "updating with 778, 778 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 193us/step - loss: 0.1770\n",
      "player 1 wins: 24\n",
      "player 2 wins: 8\n",
      "neural network update time: 0.9737241268157959 seconds.\n",
      "eval score on batch: 0.18648912082007274\n",
      "epsilons agent1 and agent2: 0.24048917686171375 0.8016305895390458\n",
      "861/861 [==============================] - 0s 52us/step\n",
      "updating with 861, 861 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 197us/step - loss: 0.1787\n",
      "player 1 wins: 23\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.9922711849212646 seconds.\n",
      "eval score on batch: 0.1724000787243472\n",
      "epsilons agent1 and agent2: 0.23808428509309662 0.7936142836436553\n",
      "823/823 [==============================] - 0s 47us/step\n",
      "updating with 823, 823 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 202us/step - loss: 0.1774\n",
      "player 1 wins: 23\n",
      "player 2 wins: 8\n",
      "neural network update time: 1.0209016799926758 seconds.\n",
      "eval score on batch: 0.17044015633867984\n",
      "epsilons agent1 and agent2: 0.23570344224216566 0.7856781408072188\n"
     ]
    }
   ],
   "source": [
    "returns = big_sim_parallel_nn(agent1, agent2, n_steps=25, games_per_step=32, nn_to_update=[nn_1], parallel_threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765/765 [==============================] - 0s 52us/step\n",
      "updating with 765, 765 training batch.\n",
      "Epoch 1/1\n",
      "765/765 [==============================] - 0s 212us/step - loss: 0.1616\n",
      "player 1 wins: 25\n",
      "player 2 wins: 6\n",
      "neural network update time: 0.16590213775634766 seconds.\n",
      "eval score on batch: 0.1615768463003869\n",
      "epsilons agent1 and agent2: 0.233346407819744 0.7778213593991465\n",
      "813/813 [==============================] - 0s 63us/step\n",
      "updating with 813, 813 training batch.\n",
      "Epoch 1/1\n",
      "1578/1578 [==============================] - 0s 215us/step - loss: 0.1642\n",
      "player 1 wins: 25\n",
      "player 2 wins: 7\n",
      "neural network update time: 0.3450188636779785 seconds.\n",
      "eval score on batch: 0.16841471841533612\n",
      "epsilons agent1 and agent2: 0.23101294374154654 0.7700431458051551\n",
      "804/804 [==============================] - 0s 62us/step\n",
      "updating with 804, 804 training batch.\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 0s 207us/step - loss: 0.1603\n",
      "player 1 wins: 25\n",
      "player 2 wins: 6\n",
      "neural network update time: 0.5008180141448975 seconds.\n",
      "eval score on batch: 0.15426476689493424\n",
      "epsilons agent1 and agent2: 0.22870281430413109 0.7623427143471035\n",
      "723/723 [==============================] - 0s 42us/step\n",
      "updating with 723, 723 training batch.\n",
      "Epoch 1/1\n",
      "3105/3105 [==============================] - 1s 200us/step - loss: 0.1691\n",
      "player 1 wins: 21\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.627734899520874 seconds.\n",
      "eval score on batch: 0.2017189643705163\n",
      "epsilons agent1 and agent2: 0.22641578616108976 0.7547192872036325\n",
      "743/743 [==============================] - 0s 57us/step\n",
      "updating with 743, 743 training batch.\n",
      "Epoch 1/1\n",
      "3848/3848 [==============================] - 1s 207us/step - loss: 0.1744\n",
      "player 1 wins: 21\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.8027827739715576 seconds.\n",
      "eval score on batch: 0.19360756097940546\n",
      "epsilons agent1 and agent2: 0.22415162829947885 0.7471720943315961\n",
      "694/694 [==============================] - 0s 51us/step\n",
      "updating with 694, 694 training batch.\n",
      "Epoch 1/1\n",
      "4542/4542 [==============================] - 1s 181us/step - loss: 0.1772\n",
      "player 1 wins: 18\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.8283779621124268 seconds.\n",
      "eval score on batch: 0.1993499414764495\n",
      "epsilons agent1 and agent2: 0.22191011201648406 0.7397003733882802\n",
      "830/830 [==============================] - 0s 41us/step\n",
      "updating with 830, 830 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 185us/step - loss: 0.1753\n",
      "player 1 wins: 24\n",
      "player 2 wins: 8\n",
      "neural network update time: 0.9322738647460938 seconds.\n",
      "eval score on batch: 0.1703338783548539\n",
      "epsilons agent1 and agent2: 0.2196910108963192 0.7323033696543974\n",
      "753/753 [==============================] - 0s 53us/step\n",
      "updating with 753, 753 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 176us/step - loss: 0.1803\n",
      "player 1 wins: 21\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.886603832244873 seconds.\n",
      "eval score on batch: 0.18747269819307563\n",
      "epsilons agent1 and agent2: 0.217494100787356 0.7249803359578534\n",
      "783/783 [==============================] - 0s 52us/step\n",
      "updating with 783, 783 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 196us/step - loss: 0.1843\n",
      "player 1 wins: 24\n",
      "player 2 wins: 8\n",
      "neural network update time: 0.9883420467376709 seconds.\n",
      "eval score on batch: 0.18008708837769194\n",
      "epsilons agent1 and agent2: 0.21531915977948246 0.7177305325982748\n",
      "816/816 [==============================] - 0s 42us/step\n",
      "updating with 816, 816 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 215us/step - loss: 0.1803\n",
      "player 1 wins: 25\n",
      "player 2 wins: 7\n",
      "neural network update time: 1.0813357830047607 seconds.\n",
      "eval score on batch: 0.16508626411942876\n",
      "epsilons agent1 and agent2: 0.21316596818168762 0.7105532272722921\n",
      "749/749 [==============================] - 0s 60us/step\n",
      "updating with 749, 749 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 231us/step - loss: 0.1816\n",
      "player 1 wins: 25\n",
      "player 2 wins: 7\n",
      "neural network update time: 1.1647989749908447 seconds.\n",
      "eval score on batch: 0.17748066364850934\n",
      "epsilons agent1 and agent2: 0.21103430849987073 0.7034476949995692\n",
      "824/824 [==============================] - 0s 43us/step\n",
      "updating with 824, 824 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 186us/step - loss: 0.1735\n",
      "player 1 wins: 24\n",
      "player 2 wins: 8\n",
      "neural network update time: 0.9396250247955322 seconds.\n",
      "eval score on batch: 0.16832895649289623\n",
      "epsilons agent1 and agent2: 0.20892396541487201 0.6964132180495735\n",
      "825/825 [==============================] - 0s 44us/step\n",
      "updating with 825, 825 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 191us/step - loss: 0.1737\n",
      "player 1 wins: 23\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.9608559608459473 seconds.\n",
      "eval score on batch: 0.1790343189239502\n",
      "epsilons agent1 and agent2: 0.2068347257607233 0.6894490858690777\n",
      "771/771 [==============================] - 0s 42us/step\n",
      "updating with 771, 771 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 189us/step - loss: 0.1757\n",
      "player 1 wins: 23\n",
      "player 2 wins: 7\n",
      "neural network update time: 0.9532260894775391 seconds.\n",
      "eval score on batch: 0.16865119751513816\n",
      "epsilons agent1 and agent2: 0.20476637850311605 0.682554595010387\n",
      "743/743 [==============================] - 0s 44us/step\n",
      "updating with 743, 743 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 201us/step - loss: 0.1710\n",
      "player 1 wins: 25\n",
      "player 2 wins: 6\n",
      "neural network update time: 1.0144360065460205 seconds.\n",
      "eval score on batch: 0.16987207425384712\n",
      "epsilons agent1 and agent2: 0.2027187147180849 0.6757290490602831\n",
      "843/843 [==============================] - 0s 59us/step\n",
      "updating with 843, 843 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 201us/step - loss: 0.1733\n",
      "player 1 wins: 23\n",
      "player 2 wins: 9\n",
      "neural network update time: 1.0136539936065674 seconds.\n",
      "eval score on batch: 0.17458466040953763\n",
      "epsilons agent1 and agent2: 0.20069152757090403 0.6689717585696803\n",
      "861/861 [==============================] - 0s 56us/step\n",
      "updating with 861, 861 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 201us/step - loss: 0.1706\n",
      "player 1 wins: 23\n",
      "player 2 wins: 8\n",
      "neural network update time: 1.016624927520752 seconds.\n",
      "eval score on batch: 0.16614921627248205\n",
      "epsilons agent1 and agent2: 0.198684612295195 0.6622820409839835\n",
      "805/805 [==============================] - 0s 46us/step\n",
      "updating with 805, 805 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 188us/step - loss: 0.1776\n",
      "player 1 wins: 21\n",
      "player 2 wins: 11\n",
      "neural network update time: 0.9474451541900635 seconds.\n",
      "eval score on batch: 0.19628066197500466\n",
      "epsilons agent1 and agent2: 0.19669776617224305 0.6556592205741436\n",
      "824/824 [==============================] - 0s 52us/step\n",
      "updating with 824, 824 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 201us/step - loss: 0.1786\n",
      "player 1 wins: 22\n",
      "player 2 wins: 10\n",
      "neural network update time: 1.0108678340911865 seconds.\n",
      "eval score on batch: 0.1894961155734016\n",
      "epsilons agent1 and agent2: 0.1947307885105206 0.6491026283684022\n",
      "813/813 [==============================] - 0s 42us/step\n",
      "updating with 813, 813 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 211us/step - loss: 0.1777\n",
      "player 1 wins: 23\n",
      "player 2 wins: 9\n",
      "neural network update time: 1.0653870105743408 seconds.\n",
      "eval score on batch: 0.18184622232819395\n",
      "epsilons agent1 and agent2: 0.1927834806254154 0.6426116020847181\n",
      "876/876 [==============================] - 0s 47us/step\n",
      "updating with 876, 876 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 197us/step - loss: 0.1794\n",
      "player 1 wins: 23\n",
      "player 2 wins: 9\n",
      "neural network update time: 0.9900689125061035 seconds.\n",
      "eval score on batch: 0.16894972920694207\n",
      "epsilons agent1 and agent2: 0.19085564581916123 0.6361854860638709\n",
      "786/786 [==============================] - 0s 44us/step\n",
      "updating with 786, 786 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 228us/step - loss: 0.1791\n",
      "player 1 wins: 25\n",
      "player 2 wins: 7\n",
      "neural network update time: 1.1474411487579346 seconds.\n",
      "eval score on batch: 0.17475027068572607\n",
      "epsilons agent1 and agent2: 0.18894708936096963 0.6298236312032323\n",
      "825/825 [==============================] - 0s 52us/step\n",
      "updating with 825, 825 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 192us/step - loss: 0.1765\n",
      "player 1 wins: 27\n",
      "player 2 wins: 5\n",
      "neural network update time: 0.9708609580993652 seconds.\n",
      "eval score on batch: 0.15048239225691015\n",
      "epsilons agent1 and agent2: 0.18705761846735994 0.6235253948912\n",
      "786/786 [==============================] - 0s 48us/step\n",
      "updating with 786, 786 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 209us/step - loss: 0.1714\n",
      "player 1 wins: 25\n",
      "player 2 wins: 6\n",
      "neural network update time: 1.0533289909362793 seconds.\n",
      "eval score on batch: 0.15921842722037366\n",
      "epsilons agent1 and agent2: 0.18518704228268634 0.617290140942288\n",
      "813/813 [==============================] - 0s 49us/step\n",
      "updating with 813, 813 training batch.\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1s 190us/step - loss: 0.1653\n",
      "player 1 wins: 27\n",
      "player 2 wins: 5\n",
      "neural network update time: 0.9592461585998535 seconds.\n",
      "eval score on batch: 0.14500809658827377\n",
      "epsilons agent1 and agent2: 0.18333517185985948 0.6111172395328651\n"
     ]
    }
   ],
   "source": [
    "returns2 = big_sim_parallel_nn(agent1, agent2, n_steps=25, games_per_step=32, nn_to_update=[nn_1], parallel_threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_step 0 updating with 690, 690 training batch.\n",
      "player 1 wins: 29\n",
      "player 2 wins: 3\n",
      "neural network update time: 0.00025177001953125 seconds.\n",
      "epsilons agent1 and agent2: 0 1\n"
     ]
    }
   ],
   "source": [
    "random_agent = nn_agent(player = -1,  nn = nn_1, epsilon_min = 0, epsilon = 1, epsilon_decay = 1)  # no decay, fully random\n",
    "agent1.epsilon = 0 # set agent1 to no random moves\n",
    "returns3 = big_sim_parallel_nn(agent1, random_agent, n_steps=1, games_per_step=32, nn_to_update=[], parallel_threads=6) # no update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_winning_pc = [x/32 for x in winner_list]\n",
    "steps = list(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f895ca81f28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(figsize = (9,5))\n",
    "ax.plot(steps, eps1, label = \"epsilon agent1\")\n",
    "ax.plot(steps, eps2, label = \"epsilon agent2\")\n",
    "ax.plot(steps, p1_winning_pc, label = 'agent1_winning_%')\n",
    "ax.set_title('Agent Epsilon and Winning Percantage for each 32 game batch')\n",
    "ax.set_xlabel('Simulation Batch Number')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
